{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prerequisite:\n",
    "\n",
    "`%pip install word2word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"de2ru\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanup(name:str,lang:str=\"en\"):\n",
    "\n",
    "    raw_content = open(f\"../static/books/{name}/{lang}.raw\", \"r\").read()\n",
    "\n",
    "    raw_content = raw_content.replace(\"\\n\",\" \")\n",
    "    raw_content = raw_content.replace(\"Mr.\",\"Mr<dot>\")\n",
    "    raw_content = raw_content.replace(\"Mrs.\",\"Mrs<dot>\")\n",
    "    raw_content = raw_content.replace(\". .\",\"..\")\n",
    "    raw_content = raw_content.replace(\". .\",\"..\")\n",
    "    raw_content = raw_content.replace(\"...\",\"…\")\n",
    "\n",
    "    raw_content = raw_content.replace(\". \",\".\\n\")\n",
    "    raw_content = raw_content.replace(\"? \",\"?\\n\")\n",
    "    raw_content = raw_content.replace(\"! \",\"!\\n\")\n",
    "    raw_content = raw_content.replace(\"\\n\\n\",\"\\n\")\n",
    "\n",
    "    raw_content = raw_content.replace(\"\\n\\\"\\n\",\"\\\"\\n\")\n",
    "\n",
    "\n",
    "    raw_content = raw_content.replace(\"<dot>\",\".\")\n",
    "\n",
    "    lines = raw_content.split(\"\\n\")\n",
    "\n",
    "    lines = map(lambda x: x.strip(), lines)\n",
    "    lines = map(lambda x: x.strip(\"\\n\"), lines)\n",
    "    \n",
    "    parts = [\"\"]\n",
    "\n",
    "    min_content = 100\n",
    "\n",
    "    max_content = 200\n",
    "\n",
    "    # for line in lines:\n",
    "    #     if len (parts[-1]) < min_content and len(parts[-1] + line) < max_content: \n",
    "    #         parts[-1] += \"\\n\" + line\n",
    "    #     else:\n",
    "    #         parts.append(line)\n",
    "\n",
    "    parts = list(lines)\n",
    "\n",
    "    parts[0] = parts[0].strip(\"\\n\")\n",
    "    \n",
    "    print(\"num parts\",len(parts))\n",
    "    # longest part \n",
    "    print(\"longest part\",max([len(part) for part in parts]))\n",
    "\n",
    "\n",
    "    # json.dump(parts, open(f\"../static/books/{name}/{lang}.json\", \"w\"),indent=4)\n",
    "\n",
    "    with open(f\"../static/books/{name}/{lang}.lines\", \"w\") as outfile:\n",
    "        for line in parts:\n",
    "            outfile.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# cleanup(\"the_little_prince\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parts 101\n",
      "longest part 691\n"
     ]
    }
   ],
   "source": [
    "cleanup(\"mobydick\",\"en\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## book collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookCollection:\n",
    "    def __init__(self, data:dict[str,dict[str,list[str]]] = {}):\n",
    "        self.data = data\n",
    "    \n",
    "    def add_book(self, lang:str,title:str, txt:list[str]):\n",
    "        if lang in self.data:\n",
    "            self.data[lang][title] = txt\n",
    "        else:\n",
    "            self.data[lang] = {title:txt}\n",
    "\n",
    "    def get_book(self, lang:str, title:str):\n",
    "\n",
    "        if lang in self.data and title in self.data[lang]:\n",
    "            return self.data[lang][title]\n",
    "\n",
    "        else:\n",
    "            \n",
    "            dir = f\"../static/books/{title}/{lang}.lines\"\n",
    "            if os.path.exists(dir):\n",
    "                book = []\n",
    "                for line in open(dir,\"r\"):\n",
    "                    book.append(line.strip())\n",
    "                self.add_book(lang,title,book)\n",
    "                return book\n",
    "            else:\n",
    "                print(\"no such book\",dir)\n",
    "                return None\n",
    "    def remove_book (self, lang:str, title:str):\n",
    "        if lang in self.data and title in self.data[lang]:\n",
    "            del self.data[lang][title]\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "bookcollection = BookCollection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_text = bookcollection.get_book(\"de\",\"mobydick\")\n",
    "ru_text = bookcollection.get_book(\"ru\",\"mobydick\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## brige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_language = \"German\"\n",
    "\n",
    "\n",
    "prompts = {\n",
    "    \"de2ru\": '''Ich versuche russisch zu lernen, indem ich ein Buch lese. Der Originaltext lautet [{}] die deutsche Version lautet [{}]\n",
    "finde alle deutschen Wörter und die passende russische Übersetzung aus dem Text und gib sie im JSON-Format an, wie hier: [[\"Apfel\",\"яблоко\"],[\"essen\", \"есть\"]]\n",
    "KI: Hier ist eine Liste von Übersetzungen im JSON-Format: [[\"''',\n",
    "\n",
    "    \"en2de\": '''I am trying to learn german by reading a book. the original text is [{}] the german version is [{}]\n",
    "translate the german words and put the translations for single words in json format like this: [[\"apple\", \"Apfel\"],[\"eat\", \"essen\"]]\n",
    "AI: here is a list of translations: [[\"'''\n",
    "}\n",
    "\n",
    "def get_translations(origin_sentence,translation_sentence,lang=\"en2de\"):\n",
    "\n",
    "    prompt = prompts[lang].format(origin_sentence,translation_sentence)\n",
    "\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages= [{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = 500,\n",
    "        stop = \"]]\"\n",
    "    )\n",
    "\n",
    "    txt = resp.choices[0].message.content\n",
    "    answer = '[[\"'+txt + \"]]\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor einigen Jahren - ich weiß nicht, wie lange genau - hatte ich wenig oder gar kein Geld in der Tasche und nichts Besonderes, was mich an Land interessierte, und so dachte ich, ich würde ein wenig herumsegeln und den wässrigen Teil der Welt sehen.\n",
      "\n",
      "Несколько лет назад - неважно, как давно, - когда в моем кошельке почти не было денег, а на берегу не было ничего особенного, что могло бы меня заинтересовать, я решил немного поплавать и посмотреть водную часть мира.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[[\"Jahre\",\"годы\"],[\"nicht\",\"не\"],[\"wie\",\"как\"],[\"davno\",\"давно\"],[\"in\",\"в\"],[\"meinem\",\"моем\"],[\"Körper\",\"тело\"],[\"schwer\",\"тяжелый\"],[\"Schritt\",\"шаг\"],[\"vorwärts\",\"вперед\"],[\"gegen\",\"против\"],[\"Wind\",\"ветер\"],[\"zu\",\"к\"],[\"haben\",\"иметь\"],[\"Wasser\",\"вода\"],[\"sehen\",\"видеть\"],[\"Segel\",\"парус\"],[\"umhersegeln\",\"плавать\"]]'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "i=1\n",
    "# get_translations(en_text[i],de_text[i])\n",
    "\n",
    "print(de_text[i])\n",
    "print()\n",
    "print(ru_text[i])\n",
    "print()\n",
    "\n",
    "get_translations(de_text[i], ru_text[i],lang=\"de2ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BridgeCollection:\n",
    "    \n",
    "    def __init__(self, data:dict[str,dict[str,list[str]]] = {}):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translating 101 sentences\n",
      ".......39\n",
      "..That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 4ce43ba3ffe79c7e349239f2b00566e3 in your message.)\n",
      "........49\n",
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09644f995df6b621a473ea117b92459b in your message.)\n",
      ".....That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b1eae5d2aa928d68d447fb7f87c6a6eb in your message.)\n",
      ".....59\n",
      "......That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d02a6fb5d601ea7f28d2165406b8611a in your message.)\n",
      "....69\n",
      "..........79\n",
      "..That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 0b85dd0c1cfcb20e6e574acdf34d20cb in your message.)\n",
      "........89\n",
      "..........99\n",
      "."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n = len(de_text)\n",
    "\n",
    "print(f\"translating {n} sentences\")\n",
    "for i in range(len(translations),n):\n",
    "\n",
    "    params = [de_text[i],ru_text[i],\"de2ru\"]\n",
    "    try:\n",
    "        new_t = get_translations(*params)\n",
    "        translations.append(new_t)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        # retry once\n",
    "        try:\n",
    "            new_t = get_translations(*params)\n",
    "            translations.append(new_t)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            translations.append(\"<error>\")\n",
    "    \n",
    "    print(\".\",end=\"\")\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'<error>' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m translations\u001b[39m.\u001b[39;49mindex(\u001b[39m\"\u001b[39;49m\u001b[39m<error>\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mValueError\u001b[0m: '<error>' is not in list"
     ]
    }
   ],
   "source": [
    "translations.index(\"<error>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor einigen Jahren - ich weiß nicht, wie lange genau - hatte ich wenig oder gar kein Geld in der Tasche und nichts Besonderes, was mich an Land interessierte, und so dachte ich, ich würde ein wenig herumsegeln und den wässrigen Teil der Welt sehen.\n",
      "\n",
      "Несколько лет назад - неважно, как давно, - когда в моем кошельке почти не было денег, а на берегу не было ничего особенного, что могло бы меня заинтересовать, я решил немного поплавать и посмотреть водную часть мира.\n"
     ]
    }
   ],
   "source": [
    "print(de_text[1])\n",
    "print()\n",
    "print(ru_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reasorb translations\n",
    "\n",
    "data =[]\n",
    "\n",
    "for bridge in bridges:\n",
    "    origin, target = bridge\n",
    "    sub = []\n",
    "    for item in origin:\n",
    "        if type(item)==list:\n",
    "            sub.append(item)\n",
    "\n",
    "    data.append(sub)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lsdkjf'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"lsxxxdkjf\".replace(\"x\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid control character at: line 1 column 171 (char 170) [[\"Utunchennaya aktivnost, s kotoroy chelovek poluchaet den'gi, poistinе udivitеlna,если uchest', что my tak iskrennе smotrim na den'gi kak koren' vsey zemnoy bеdы, icht…\n",
      "Translated into English: \n",
      "[[\"Sophisticated activity, with which a person receives money, is truly amazing, considering that we sincerely believe that money is the root of all worldly evils, and that no wealthy person will enter paradise.\"]]\n",
      "Unterminated string starting at: line 1 column 1095 (char 1094) [[\"Ich\", \"я\"], [\"kann\", \"могу\"], [\"zwar\", \"правда\"], [\"nicht\", \"не\"], [\"genau\", \"точно\"], [\"sagen\", \"сказать\"], [\"warum\", \"почему\"], [\"die\", \"те\"], [\"Bühnenleiter\", \"распорядители сцены\"], [\"das\", \"это\"], [\"Schicksal\", \"судьба\"], [\"mich\", \"меня\"], [\"für\", \"на\"], [\"diese\", \"эту\"], [\"schäbige\", \"убогую\"], [\"Rolle\", \"роль\"], [\"einer\", \"одном\"], [\"Walfangfahrt\", \"китобойного судна\"], [\"vorgesehen\", \"назначили\"], [\"haben\", \"был\"], [\"während\", \"в то время как\"], [\"andere\", \"других\"], [\"prächtige\", \"великолепные\"], [\"Rollen\", \"роли\"], [\"in\", \"в\"], [\"hohen\", \"высоких\"], [\"Tragödien\", \"трагедиях\"], [\"kurze\", \"короткие\"], [\"und\", \"и\"], [\"leichte\", \"легкие\"], [\"in\", \"в\"], [\"vornehmeren\", \"благородных\"], [\"Komödien\", \"комедиях\"], [\"lustige\", \"веселые\"], [\"Farcen\", \"фарсах\"], [\"ich\", \"я\"], [\"kann\", \"могу\"], [\"zwar\", \"правда\"], [\"nicht\", \"не\"], [\"genau\", \"точно\"], [\"sagen\", \"сказать\"], [\"warum\", \"почему\"], [\"das\", \"это\"], [\"so\", \"так\"], [\"war\", \"было\"], [\"Doch\", \"Однако\"], [\"jetzt\", \"теперь\"], [\"da\", \"когда\"], [\"ich\", \"я\"], [\"mich\", \"вспоминаю\"], [\"an\", \"все\"], [\"alle\", \"все\"], [\"Umstände\", \"обстоят]]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for t in translations:\n",
    "\n",
    "    t=  t.replace(\".]\",\"]\")\n",
    "    t = t.replace(\"]]]\",\"]]\")\n",
    "    t = t.replace(\"]]]\",\"]]\")\n",
    "\n",
    "    if not t.endswith(\"]]\"):\n",
    "        t = t[:t.rfind(\"]\")+1]\n",
    "    if not t.endswith(\"]]\"):\n",
    "        t = t + \"]\"\n",
    "\n",
    "    if not t.endswith(\"\\\"]]\"):\n",
    "        t.replace(\"]]\", \"\\\"]\")\n",
    "\n",
    "    data_point = []\n",
    "    try:\n",
    "        data_point = (json.loads(t))\n",
    "    except Exception as e:\n",
    "        print(e,t)\n",
    "        # try:\n",
    "        #     data_point = (json.loads(t[:t.rfind(\"]\")+1]+\"]\"))\n",
    "        # except Exception as e:\n",
    "\n",
    "        #     print(\"final try run \",e,t)\n",
    "\n",
    "\n",
    "    data_point = filter(lambda x: len(x)==2, data_point)\n",
    "    data.append(list(data_point))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mein', 'мой'],\n",
       " ['Weg', 'способ'],\n",
       " ['vertreiben', 'разогнать'],\n",
       " ['Milz', 'селезенка'],\n",
       " ['und', 'и'],\n",
       " ['regulieren', 'наладить'],\n",
       " ['Kreislauf', 'кровообращение']]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[[\"Nennt\",\"называйте\"],[\"mich\",\"меня\"],[\"Ishmael\",\"Измаил\"],[\"die\",\"ди\"],[\"deutsche\",\"немецкие\"],[\"Version\",\"версия\"],[\"übersetze\",\"переводить\"],[\"alle\",\"все\"],[\"Wörter\",\"слова\"],[\"gib\",\"дайте\"],[\"die\",\"ту\"],[\"Übersetzungen\",\"переводы\"],[\"für\",\"для\"],[\"einzelne\",\"отдельные\"]]',\n",
       " '[[\"Jahre\",\"года\"],[\"nicht\",\"не\"],[\"wie\",\"как\"],[\"wenn\",\"когда\"],[\"mein\",\"мой\"],[\"Tasche\",\"кошелек\"],[\"gar\",\"совсем\"],[\"Geld\",\"деньги\"],[\"interessieren\",\"интересовать\"],[\"etwas\",\"что-то\"],[\"Besonderes\",\"особенное\"],[\"an\",\"к\",\"на\"],[\"Land\",\"земля\"],[\"und\",\"и\"],[\"so\",\"так\"],[\"denken\",\"думать\"],[\"ein wenig\",\"немного\"],[\"herumsegeln\",\"поплавать\"],[\"wässrig\",\"водный\"],[\"Teil\",\"часть\"],[\"Welt\",\"мир\"]]']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2word :\n",
    "    \n",
    "    def __init__(self, from_language:str, to_language:str):\n",
    "        self.from_language = from_language\n",
    "        self.to_language = to_language\n",
    "        self.data:dict[str,set[str]] = {}\n",
    "        self.anti:dict[str,set[str]] = {}\n",
    "\n",
    "    def add_translation(self, from_word:str, to_word:str):\n",
    "\n",
    "        if from_word not in self.data:\n",
    "            self.data[from_word] = {to_word}\n",
    "        else:\n",
    "            self.data[from_word].add(to_word)\n",
    "\n",
    "        if to_word not in self.anti:\n",
    "            self.anti[to_word] = {from_word}\n",
    "        else:\n",
    "            self.anti[to_word].add(from_word)\n",
    "\n",
    "    def get_translations(self, from_word:str):\n",
    "        if from_word in self.data:\n",
    "            return self.data[from_word]\n",
    "        else:\n",
    "            return set()\n",
    "\n",
    "    def save(self):\n",
    "        with open(f\"../static/translations/{self.from_language}_{self.to_language}.json\", \"w\") as f:\n",
    "            data_obj = {}\n",
    "            for k,v in self.data.items():\n",
    "                data_obj[k] = list(v)\n",
    "\n",
    "            json.dump(data_obj, f,indent=4)\n",
    "\n",
    "        with open(f\"../static/translations/{self.to_language}_{self.from_language}.json\", \"w\") as f:\n",
    "            data_obj = {}\n",
    "            for k,v in self.anti.items():\n",
    "                data_obj[k] = list(v)\n",
    "\n",
    "            json.dump(data_obj, f,indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "de2en = Word2word(\"de\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    for t in d:\n",
    "        de2en.add_translation(t[0],t[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2WordCollection:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "    \n",
    "    def add(self, vocab: tuple[str,str], lang:str = \"de2en\"):\n",
    "        \n",
    "        origin,target =  lang.split(\"2\")\n",
    "\n",
    "        anti_lang = target + \"2\" + origin\n",
    "        anti_vocab = (vocab[1],vocab[0])\n",
    "\n",
    "        self._add(vocab,lang)\n",
    "        self._add(anti_vocab,anti_lang)\n",
    "\n",
    "    \n",
    "    def _add(self,vocab,lang:str):\n",
    "\n",
    "        if lang not in self.data:\n",
    "            self.data[lang] = {}\n",
    "        \n",
    "        item = self.data[lang]\n",
    "        if vocab[0] not in item:\n",
    "            item[vocab[0]] = [vocab[1]]\n",
    "        else:\n",
    "            item[vocab[0]].append(vocab[1])\n",
    "\n",
    "    def save (self):\n",
    "        for lang, vocab in self.data.items():\n",
    "            with open(f\"../static/translations/{lang}.json\", \"w\") as f:\n",
    "                json.dump(vocab, f,indent=4)\n",
    "\n",
    "\n",
    "w2wc = Word2WordCollection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add de to russian\n",
    "w2wc.add((\"Apfel\",\"яблоко\"),\"de2ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de2ru': {'Apfel': ['яблоко']}, 'ru2de': {'яблоко': ['Apfel']}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2wc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data: \n",
    "    for v in d:\n",
    "        w2wc.add(v,\"de2ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2wc.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bridge  = list[list[list[(str|list[str])]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Vor einigen Jahren - ich weiß ',\n",
       "  ['не', 'nicht'],\n",
       "  ', ',\n",
       "  ['как', 'wie'],\n",
       "  ' lange genau - hatte ich wenig oder ',\n",
       "  ['совсем', 'gar'],\n",
       "  ' kein ',\n",
       "  ['деньги', 'Geld'],\n",
       "  ' in der ',\n",
       "  ['кошелек', 'Tasche'],\n",
       "  ' ',\n",
       "  ['и', 'und'],\n",
       "  ' nichts ',\n",
       "  ['особенное', 'Besonderes'],\n",
       "  ', was mich an ',\n",
       "  ['земля', 'Land'],\n",
       "  ' interessierte, ',\n",
       "  ['и', 'und'],\n",
       "  ' ',\n",
       "  ['так', 'so'],\n",
       "  ' dachte ich, ich würde ',\n",
       "  ['немного', 'ein wenig'],\n",
       "  ' ',\n",
       "  ['поплавать', 'herumsegeln'],\n",
       "  ' ',\n",
       "  ['и', 'und'],\n",
       "  ' den wässrigen ',\n",
       "  ['часть', 'Teil'],\n",
       "  ' der ',\n",
       "  ['мир', 'Welt'],\n",
       "  ' sehen.'],\n",
       " ['Несколько лет назад - неважно, ',\n",
       "  ['wie', 'как'],\n",
       "  ' давно, - ',\n",
       "  ['wenn', 'когда'],\n",
       "  ' в моем кошельке почти ',\n",
       "  ['nicht', 'не'],\n",
       "  ' было денег, а на берегу ',\n",
       "  ['nicht', 'не'],\n",
       "  ' было ничего особенного, что могло бы меня заинтересовать, я решил ',\n",
       "  ['ein wenig', 'немного'],\n",
       "  ' ',\n",
       "  ['herumsegeln', 'поплавать'],\n",
       "  ' ',\n",
       "  ['und', 'и'],\n",
       "  ' посмотреть водную ',\n",
       "  ['Teil', 'часть'],\n",
       "  ' мира.']]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_bridge(origins:list[str], translations:list[str], translatorlist:list[list[list[str]]])->Bridge:\n",
    "    res = []\n",
    "    for origin, translation, translator in zip(origins, translations,translatorlist):\n",
    "\n",
    "        origin_data = [origin]\n",
    "        translation_data = [translation]\n",
    "        \n",
    "        for a,b in translator:\n",
    "\n",
    "            for d in origin_data:\n",
    "                if type (d) == str:\n",
    "                    insert_translations(d,a,b,origin_data)\n",
    "\n",
    "            for d in translation_data:\n",
    "                if type (d) == str:\n",
    "                    insert_translations(d,b,a,translation_data)\n",
    "\n",
    "        res.append([origin_data, translation_data])\n",
    "\n",
    "    return res\n",
    "\n",
    "def insert_translations(sentence:str, origin:str, target:str, origin_data):\n",
    "    pattern = r'\\b' + re.escape(origin.lower()) + r'\\b'\n",
    "\n",
    "    matches = re.finditer(pattern, sentence.lower())\n",
    "    for match in matches:\n",
    "        pre = sentence[:match.start()]\n",
    "        core = [target,sentence[match.start():match.end()]]\n",
    "        post = sentence[match.end():]\n",
    "        idx = origin_data.index(sentence)\n",
    "        origin_data.remove(sentence)\n",
    "        origin_data.insert(idx,pre)\n",
    "        origin_data.insert(idx+1,core)\n",
    "        origin_data.insert(idx+2,post)\n",
    "        break\n",
    "\n",
    "# make_bridge([\"Vor einigen Jahren sah er mich\"], [\"Some years ago he saw me\"], [[[\"einigen\", \"Some\"],[\"mich\",\"me\"]]])\n",
    "\n",
    "i = 2\n",
    "make_bridge (de_text[:i],ru_text[:i],data[:i])[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = make_bridge (de_text,ru_text,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sollten ',\n",
       "  ['вы', 'Sie'],\n",
       "  ' ',\n",
       "  ['когда-нибудь', 'jemals'],\n",
       "  ' ',\n",
       "  ['в', 'in'],\n",
       "  ' ',\n",
       "  ['в', 'der'],\n",
       "  ' ',\n",
       "  ['большой', 'großen'],\n",
       "  ' ',\n",
       "  ['американской', 'amerikanischen'],\n",
       "  ' ',\n",
       "  ['пустыне', 'Wüste'],\n",
       "  ' ',\n",
       "  ['испытаете жажду', 'durstig'],\n",
       "  ' ',\n",
       "  ['быть', 'sein'],\n",
       "  ', ',\n",
       "  ['попробуйте', 'versuchen'],\n",
       "  ' ',\n",
       "  ['вы', 'Sie'],\n",
       "  ' ',\n",
       "  ['этот', 'dieses'],\n",
       "  ' ',\n",
       "  ['эксперимент', 'Experiment'],\n",
       "  ', ',\n",
       "  ['если', 'wenn'],\n",
       "  ' ',\n",
       "  ['вашем', 'Ihre'],\n",
       "  ' ',\n",
       "  ['караване', 'Karawane'],\n",
       "  ' ',\n",
       "  ['окажется', 'zufällig'],\n",
       "  ' ',\n",
       "  ['с', 'mit'],\n",
       "  ' ',\n",
       "  ['одним', 'einem'],\n",
       "  ' ',\n",
       "  ['метафизическим', 'metaphysischen'],\n",
       "  ' ',\n",
       "  ['профессором', 'Professor'],\n",
       "  ' ',\n",
       "  ['оснащённым', 'ausgestattet'],\n",
       "  ' ',\n",
       "  ['есть', 'ist'],\n",
       "  '.'],\n",
       " ['',\n",
       "  ['wenn', 'Если'],\n",
       "  ' ',\n",
       "  ['Sie', 'вы'],\n",
       "  ' ',\n",
       "  ['jemals', 'когда-нибудь'],\n",
       "  ' ',\n",
       "  ['durstig', 'испытаете жажду'],\n",
       "  ' ',\n",
       "  ['in', 'в'],\n",
       "  ' великой ',\n",
       "  ['amerikanischen', 'американской'],\n",
       "  ' ',\n",
       "  ['Wüste', 'пустыне'],\n",
       "  ', ',\n",
       "  ['versuchen', 'попробуйте'],\n",
       "  ' провести ',\n",
       "  ['dieses', 'этот'],\n",
       "  ' ',\n",
       "  ['Experiment', 'эксперимент'],\n",
       "  ', ',\n",
       "  ['wenn', 'если'],\n",
       "  ' ',\n",
       "  ['in', 'в'],\n",
       "  ' ',\n",
       "  ['Ihre', 'вашем'],\n",
       "  ' ',\n",
       "  ['Karawane', 'караване'],\n",
       "  ' ',\n",
       "  ['zufällig', 'окажется'],\n",
       "  ' профессор метафизики.']]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridge[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (f\"../static/books/mobydick/{lang}.json\",\"w\") as f:\n",
    "    json.dump(bridge, f,indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
